# Instrucciones para Google Colab

## ðŸ“ Archivo a Subir

**Solo necesitas subir UN archivo:**
- `alphabetnet_colab.py` - Contiene todo el cÃ³digo necesario

## ðŸ“Š Datos a Subir en sample_data/

En Colab, crea una carpeta llamada `sample_data` y sube estos 2 archivos:

1. **`train_wide.parquet`** - Datos de entrenamiento
2. **`val_wide.parquet`** - Datos de validaciÃ³n

### Estructura en Colab:
```
/content/
â”œâ”€â”€ alphabetnet_colab.py    (subir este archivo)
â””â”€â”€ sample_data/            (crear esta carpeta)
    â”œâ”€â”€ train_wide.parquet  (subir aquÃ­)
    â””â”€â”€ val_wide.parquet    (subir aquÃ­)
```

## ðŸš€ Pasos en Colab

### 1. Instalar dependencias
```python
!pip install torch numpy pandas scikit-learn matplotlib pyarrow --quiet
```

### 2. Subir archivos
- Sube `alphabetnet_colab.py` a la raÃ­z de Colab
- Crea carpeta `sample_data` y sube los 2 archivos parquet

### 3. Ejecutar todo
```python
!python alphabetnet_colab.py
```

## âœ… Resultados Generados

DespuÃ©s de ejecutar, tendrÃ¡s:

- `checkpoints/best.pt` - Mejor modelo PyTorch
- `alphabetnet.onnx` - Modelo ONNX exportado â­

## ðŸ“¥ Descargar Resultados

```python
from google.colab import files

# Descargar modelo ONNX
files.download('alphabetnet.onnx')

# Descargar mejor checkpoint
files.download('checkpoints/best.pt')
```

## ðŸ“ Notas

- El entrenamiento puede tomar 30-60 minutos
- Usa GPU en Colab para acelerar (Runtime > Change runtime type > GPU)
- Los archivos parquet deben estar en `sample_data/` (no en `data/alphabet/`)

