{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AlphabetNet - Entrenamiento en Google Colab\n",
        "\n",
        "**Tarea**: Regex → Alfabeto del Autómata\n",
        "\n",
        "Este notebook entrena AlphabetNet para predecir el alfabeto (símbolos A-L) que pertenecen a un autómata dado su expresión regular.\n",
        "\n",
        "## Métricas objetivo:\n",
        "- F1 macro ≥ 0.92\n",
        "- F1 mínimo ≥ 0.85\n",
        "- Exactitud de conjunto ≥ 0.90\n",
        "- ECE ≤ 0.05\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuración inicial\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clonar repositorio\n",
        "!git clone https://github.com/xLuisPc/ModelosLenguajes.git\n",
        "%cd ModelosLenguajes\n",
        "\n",
        "# Instalar dependencias\n",
        "%pip install -r requirements.txt -q\n",
        "\n",
        "print(\"✓ Repositorio clonado y dependencias instaladas\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar GPU\n",
        "import torch\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memoria GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "else:\n",
        "    print(\"⚠ Se usará CPU (más lento)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Preparar dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar si el dataset ya existe en el repo\n",
        "dataset_path = Path('data/dataset_regex_sigma.csv')\n",
        "\n",
        "if dataset_path.exists():\n",
        "    import pandas as pd\n",
        "    df = pd.read_csv(dataset_path)\n",
        "    print(f\"✓ Dataset encontrado: {len(df)} autómatas\")\n",
        "    print(f\"  Columnas: {list(df.columns)}\")\n",
        "    print(f\"\\n  Primeras 3 filas:\")\n",
        "    print(df.head(3))\n",
        "else:\n",
        "    print(\"✗ Dataset no encontrado\")\n",
        "    print(\"\\nOpciones:\")\n",
        "    print(\"  1. Generar desde dataset3000.csv (si está en el repo):\")\n",
        "    print(\"     !python scripts/create_regex_sigma_dataset.py\")\n",
        "    print(\"\\n  2. Subir dataset_regex_sigma.csv manualmente:\")\n",
        "    print(\"     from google.colab import files\")\n",
        "    print(\"     files.upload()\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OPCIÓN 1: Generar dataset desde dataset3000.csv (si está en el repo)\n",
        "if Path('dataset3000.csv').exists() and not dataset_path.exists():\n",
        "    print(\"Generando dataset_regex_sigma.csv desde dataset3000.csv...\")\n",
        "    !python scripts/create_regex_sigma_dataset.py\n",
        "    \n",
        "    if dataset_path.exists():\n",
        "        print(\"✓ Dataset generado exitosamente\")\n",
        "    else:\n",
        "        print(\"✗ Error al generar dataset\")\n",
        "elif not dataset_path.exists():\n",
        "    print(\"⚠ dataset_regex_sigma.csv no encontrado\")\n",
        "    print(\"⚠ dataset3000.csv tampoco encontrado\")\n",
        "    print(\"\\nNecesitas hacer una de estas opciones:\")\n",
        "    print(\"  A) Subir dataset3000.csv y ejecutar la celda anterior\")\n",
        "    print(\"  B) Subir dataset_regex_sigma.csv directamente (siguiente celda)\")\n",
        "else:\n",
        "    print(\"✓ Dataset ya existe\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### OPCIÓN 2: Subir dataset manualmente\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DESCOMENTA ESTAS LÍNEAS SI NECESITAS SUBIR EL DATASET MANUALMENTE\n",
        "# Ejecuta esta celda solo si dataset_regex_sigma.csv no está en el repo\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"SUBIR DATASET\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Instrucciones:\")\n",
        "print(\"1. Ejecuta esta celda\")\n",
        "print(\"2. Selecciona el archivo 'dataset_regex_sigma.csv' desde tu computadora\")\n",
        "print(\"3. Espera a que se complete la carga\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Descomenta la siguiente línea para activar la subida de archivos:\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# Verificar si se subió correctamente\n",
        "if dataset_path.exists():\n",
        "    print(f\"\\n✓ Dataset encontrado: {dataset_path}\")\n",
        "    import pandas as pd\n",
        "    df = pd.read_csv(dataset_path)\n",
        "    print(f\"  Total de autómatas: {len(df)}\")\n",
        "    print(f\"  Columnas: {list(df.columns)}\")\n",
        "else:\n",
        "    print(\"\\n⚠ Dataset no encontrado todavía.\")\n",
        "    print(\"Por favor, descomenta la línea 'uploaded = files.upload()' y ejecuta de nuevo.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Entrenamiento\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entrenar modelo\n",
        "!python train.py \\\n",
        "  --train_data data/dataset_regex_sigma.csv \\\n",
        "  --val_data data/dataset_regex_sigma.csv \\\n",
        "  --checkpoint_dir checkpoints \\\n",
        "  --use_scheduler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Búsqueda de umbrales óptimos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Buscar umbrales óptimos por símbolo\n",
        "!python find_thresholds.py \\\n",
        "  --checkpoint checkpoints/best.pt \\\n",
        "  --val_data data/dataset_regex_sigma.csv \\\n",
        "  --output_dir checkpoints\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Inferencia - Demo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ejemplo de inferencia: predecir alfabeto desde regex\n",
        "!python infer.py \\\n",
        "  --checkpoint checkpoints/best.pt \\\n",
        "  --regex \"(AB)*C\" \\\n",
        "  --thresholds checkpoints/thresholds.json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Exportar modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exportar modelo a ONNX con thresholds\n",
        "!python export_model.py \\\n",
        "  --checkpoint checkpoints/best.pt \\\n",
        "  --thresholds checkpoints/thresholds.json \\\n",
        "  --enhanced_checkpoint checkpoints/best_with_thresholds.pt \\\n",
        "  --output alphabetnet.onnx\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Descargar resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Descargar archivos importantes\n",
        "from google.colab import files\n",
        "\n",
        "files_to_download = [\n",
        "    'checkpoints/best.pt',\n",
        "    'checkpoints/best_with_thresholds.pt',\n",
        "    'checkpoints/thresholds.json',\n",
        "    'checkpoints/train_log.csv',\n",
        "    'checkpoints/threshold_eval.csv',\n",
        "    'alphabetnet.onnx'\n",
        "]\n",
        "\n",
        "print(\"Descargando archivos...\")\n",
        "for filepath in files_to_download:\n",
        "    path = Path(filepath)\n",
        "    if path.exists():\n",
        "        try:\n",
        "            files.download(str(path))\n",
        "            print(f\"✓ {filepath} descargado\")\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Error al descargar {filepath}: {e}\")\n",
        "    else:\n",
        "        print(f\"⚠ {filepath} no existe\")\n",
        "\n",
        "print(\"\\n✓ Descarga completada\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
